---
title: \vspace{2.5in} Candy Bar Analysis
subtitle: "DAPT2019 Group 5"
author: "Keedra Bond, Dennis Carter, Kyle Jacobs, Richa Singh "
date: "May 5, 2018"
output:
  pdf_document:
    keep_tex: yes
    latex_engine: pdflatex
  html_document:
    df_print: paged
geometry: margin=.5in
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
   \usepackage{graphicx}
   \usepackage{fancyhdr}
   \pagestyle{fancy}
   \setlength\headheight{28pt}
   \fancyhead[L]{\includegraphics[width=5cm]{VCU_background.png}}
   \fancyfoot[LE,RO]{GPIM}
---



```{r, echo=FALSE, out.width = "200px", fig.align='center'}
knitr::include_graphics("C:/Users/User/Desktop/R/Assignment 5/VCU_logo.png")
```

\newpage
This assignment is using the Candybars.txt file.
Libraries used for this analysis are readr, corrplot, and ggplot2.

```{r results='asis',warning=FALSE,echo=FALSE,message=FALSE}
library(kableExtra)
library(knitr)
library(readr)
library(corrplot)
library(ggplot2)
library(broom)
library(pander)
library(tinytex)
```


```{r, echo=FALSE, message=FALSE}
                  CandyBars <- read.csv("C:/Users/User/Desktop/R/Data/CandyBars.txt")

           names(CandyBars) <- c("Brand", "Name", "Oz", "Cals", "Tot.f", "Sat.f", "Chol.", "Sod",
                                "Carb", "Fiber","Sugar", "Prot", "VitA", "VitC", "Calc", "Iron")
```

##Part 1: Exploratory Data Analysis

1. Variance/Covariance matrix and the correlation matrix
\center To consider only the numeric variables, we must get rid of column 1 and 2 (Brand and Name): \center
```{r, echo=TRUE}
                                  CandyBars_sub <- CandyBars[,c(3:16)]
```

\center __Variance/Covariance Matrix__: \center
```{r, eval=FALSE}
                                     covmat <- cov(CandyBars_sub)
```

```{r, echo=FALSE, eval=FALSE}
covmat <- cov(CandyBars_sub)
x <- kable(covmat, digits = 2, align = 'l', format = "latex")
x <-row_spec(x, 0, angle = 45)
kable_styling(x, latex_options = 'scale_down')
```

```{r, echo=FALSE}
covmat <- cov(CandyBars_sub)
pander(covmat, long = TRUE, caption = "Covariance Matrix", digits = 2, latex_options = 'scale_down')
```
\newpage
\center __Correlation Matrix__: \center

```{r, eval=FALSE}
                                    corrmat <- cor(CandyBars_sub)
```

```{r, echo=FALSE}
corrmat <- cor(CandyBars_sub)
pander(corrmat, long = TRUE, digits = 2, latex_options = 'scale_down')
```

\center __Interpretation__: \center
\center Looking at the Variance/Covariance Matrix, there are some large numbers (e.g., 334 for Sodium  MG and Calories), but they are not meaningful because the variables are using different scales.  The most common measure is in grams, but there are others in milligrams, ounces, and %.  Because these are not consistent, this matrix is not helpful in interpreting the correlations among the variables. \center

\center Switching to the Correlation Matrix, we get a better sense of the relationship among the variables to each other, although, with 14 variables, it is difficult to find the correlations that are strongly positive or negative.  Calories and Total Fat G are the most correlated, with a value of 80.7%.  Total Fat G and Saturated Fat G are a close second with a value of 79.8%.  Because of the number of variables, the scatterplot matrix and color map are more useful in identifying strong relationships among the variables. \center

\newpage
2. Make a scatterplot matrix and comment on obsercations. 

\center __Scatterplot Matrix__: \center
```{r, warning=FALSE, fig.height=8, fig.width=8}
                            pairs(CandyBars_sub[1:14], data=CandyBars_sub)
```

\center __Observations__: \center 
\center There are a handful of variables, such as Vitamin A %RDI, Vitamin C %RDI, and Dietary Fiber G, that are not correlated to any other variable in this dataset.  Only a few variables have strong positive correlations to other variables, and there are no strong negative correlations between variables. \center

\newpage
3. Make a color map on the correlations and comment on observations.
\center __Color Map on Correlations__: \center
```{r, fig.height=8, fig.width=8}
                                    corrplot(corrmat,method="color")
```

\center __Observations__: \center
\center There no strong negative correlations among the variables.  There are some strong positive correlations, as exhibited by the darker blue plots in the color map produced in R and the darker red plots in the color map produced in JMP.  For example, Calories and Total Fat G are strongly correlated, as are Protein and Total Fat G. There are many variables that are not positively or negatively correlated, as shown by the white squares in the color map produced in R and the gray squares in the color map produced in JMP. \center

\newpage
4. Use a probability plot to assess the multivariate normality. Interpret results.

\center __Probability Plot__: \center
```{r, fig.height=7, fig.width=8}
                                      x <- as.matrix(CandyBars_sub)
                                      center <- colMeans(x)
                                      n <- nrow(x); 
                                      p <- ncol(x); 
                                      cov <- cov(x); 
                                      d <- mahalanobis(x,center,cov)
                                      qqplot(qchisq(ppoints(n),df=p),d,
                                             main="QQ Plot Assessing Multivariate Normality",
                                             ylab="Mahalanobis D2")
                                      abline(a=0,b=1)
```

\center __Interpretation__: \center
\center There is some departure from the line, but, because the points are fairly close to the line, we can conclude this 14-dimension dataset follows a multivariate normal distribution.  There are two outliers at the very top right of the plot that we should investigate further.  We may also interpret that the data is right skewed and look at data transformation  to get normality. \center

\newpage

##Part 2: Principal Component Analysis

a) Eigenvalues of Correlation Matrix/Scree Plot:

\center __Candy Bar PCA Analysis__: \center
```{r eval=FALSE }
                              pca <- prcomp(CandyBars[,-(1:2)], scale=TRUE)
```

```{r, echo=FALSE}
pca <- prcomp(CandyBars[,-(1:2)], scale=TRUE)
pander(pca, caption = attr(pca, "PCA"), split.table = 100)
```


\center __Summary of the PCA__: \center
```{r, eval=FALSE}
                                              summary(pca)
```

```{r, echo=FALSE}
sumpca <- summary(pca)
x <- kable(sumpca$importance, digits = 4, format = 'latex', booktabs = T)
x <-row_spec(x, 0, bold = T)
x <- column_spec(x, 1, bold = T)
kable_styling(x, latex_options = 'scale_down')
```

\newpage
\center __Scree Plot__: \center
```{r, echo=TRUE, eval=FALSE}
                                      screeplot(pca, type = "lines")
```
```{r, echo=FALSE, fig.height=4.25}
prop_varex <- sumpca$sdev^2/sum(sumpca$sdev^2)
plot(prop_varex, xlab = "Principal Component",
             ylab = "Proportion of Variance Explained",
             main = "PCA Scree Plot",
             type = "b")
```
```{r, echo=FALSE, fig.height=4.25}
plot(cumsum(prop_varex), xlab = "Principal Component",
              ylab = "Cumulative Proportion of Variance Explained",
              main = "Cumulative Proportion",
              type = "b")
```
\center   __Observation__: \center
\center Based upon the Scree Plot, we selected four principal components, which explains 70.4% of the variation in the data. \center
    
\newpage    
ii) Provide the loadings matrix. What do you learn? Interpret first two principal components.

\center __Loadings Matrix__: \center
```{r, eval=FALSE}
                                        loadings <- pca$rotation
```

```{r, echo=FALSE}
loadings <- pca$rotation
x <- kable(loadings, digits = 3, align = 'l', format = 'latex', booktabs = T)
x <-row_spec(x, 0, bold = T, angle = 45)
x <- column_spec(x, 1, bold = T)
kable_styling(x, latex_options = 'scale_down')
```
   
\center __Principal Component 1__ \center
\center (.113) oz./pkg. + (.403) calories + (.487) total fat g + (.403) saturated fat g + (.218) cholesterol g - (.012) sodium mg - (.103) carbohydrate g + (.319) dietary fiber g - (.017) sugars g + (.379) protein g + (.014) vitamin A% RDI + (.009) Vitamin C% RDI + (.296) Calcium + (.184) Iron% RDI \center
  
\center __Interpretation__: \center
\center The first principal component shows an overall nutrition score with calories, total fat, saturated fat, cholesterol, dietary fiber, protein and Calcium% RDI having larger numbers, which represent higher scores. \center

\center __Principal Component 2__ \center
\center (.0054) oz./pkg. + (.284) calories + (.119) total fat g + (.177) saturated fat g + (.045) cholesterol g + (.013) sodium mg + (.343) carbohydrate g - (.003) dietary fiber g + (.380) sugars g - (.140)  protein g - (.4069) vitamin A% RDI - (.446) vitamin C% RDI - (.281) calcium% RDI - (.380) Iron% RDI \center

\center __Interpretation__: \center
\center The second principal component shows a contrast between the candy bars' nutritional content like carbohydrate g and sugars g (moderate positive correlations) and the recommended daily intake of vitamins and minerals (moderate negative correlations). \center

\newpage

iii) Construct a biplot of the loadings and scores for the first two principal components. Are there natural groupings/unsual observations?

\center __Biplot of Loadings and Scores__: \center

```{r, fig.height=8, fig.width=8}
                          candybars_sub <- CandyBars[,-(2)]
                          Brand <- candybars_sub$Brand
                          scores <- as.data.frame(pca$x)
                          p <- ggplot(data=scores, aes(x=PC1, y=PC2,colour=Brand)) 
                          p + geom_hline(yintercept=0) + geom_vline(xintercept=0) + geom_point()
```

\center __Observation__: \center 
\center Hershey candy bars tend to have more groupings and score higher on calories, total fat, saturated fat, dietary fiber, protein, and cholesterol.  Also, the Weider brand scored higher for Vitamin A% RDI. \center
    
b) How do the results change if PCA performed on the covariance matrix instead? What do you learn from this?

\center __Candy Bar PCA Analysis - Covariance Matrix__: \center

```{r, eval=FALSE, echo=FALSE}
                                  candycov <- cov(CandyBars[,-(1:2)])
                                  pcacov <- prcomp(candycov, scale=TRUE)
                                  pcacov
                                  summary(pcacov)
                                  loadingscov <- pcacov$rotation
                                  loadingscov
```

```{r, eval=FALSE}
                                  candycov <- cov(CandyBars[,-(1:2)])
                                  pcacov <- prcomp(candycov, scale=TRUE)
```

```{r, echo=FALSE}
candycov <- cov(CandyBars[,-(1:2)])
pcacov <- prcomp(candycov, scale=TRUE)
pander(pcacov, caption = attr(pca, "PCA"), split.table = 100)
```  

\center __Summary of the Covariance PCA__: \center
```{r, eval=FALSE}
                                            summary(pcacov)
```

```{r, echo=FALSE}
sumpca <- summary(pcacov)
x <- kable(sumpca$importance, digits = 4, format = 'latex', booktabs = T)
x <-row_spec(x, 0, bold = T)
x <- column_spec(x, 1, bold = T)
kable_styling(x, latex_options = 'scale_down')
```

\newpage

\center __Covariance Loading Matrix__: \center
```{r, eval=FALSE}
                                     loadingscov <- pcacov$rotation
```

```{r, echo=FALSE}
loadingscov <- pca$rotation
x <- kable(loadingscov, digits = 3, align = 'l', format = 'latex', booktabs = T)
x <-row_spec(x, 0, bold = T, angle = 45)
x <- column_spec(x, 1, bold = T)
kable_styling(x, latex_options = 'scale_down')
```

\center The covariance matrix is more difficult to interpret than the correlation matrix.  If the measurement units or variances differ, the components of the covariance matrix will have variables with large variances.  When using the covariance matrix for this principal component analysis, 99% of the variation in the data is explained in the first 4 principal components, whereas, in the correlation matrix, the first four principal components explained only 70% of the variation in the data. \center

\center __Principal Component 1__: \center
\center Sodium, carbohydrate and sugar now have positive values, and vitamin A and vitamin C have negative values.  Overall, nutrition score with calories, total fat, saturated fat and protein have larger numbers, which represent higher scores. \center

\center __Principal Component 2__: \center
\center There is no longer a strong contrast between the candy bars nutritional content like calories and sugar with the recommended daily intake of vitamins and minerals.  Sodium has the highest score of 0.97, and most of the other values are negative. \center



    
















